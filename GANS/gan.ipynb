{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vasil\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/10000] [D loss: 0.6759275197982788] [G loss: 1.259913444519043] [ER loss: 0.20505230128765106]\n",
      "[Epoch 100/10000] [D loss: 0.7148988842964172] [G loss: 0.7579478621482849] [ER loss: 0.00725946482270956]\n",
      "[Epoch 200/10000] [D loss: 0.6965358257293701] [G loss: 0.723930299282074] [ER loss: 0.0033225363586097956]\n",
      "[Epoch 300/10000] [D loss: 0.6932430863380432] [G loss: 0.7132766246795654] [ER loss: 0.0018087847856804729]\n",
      "[Epoch 400/10000] [D loss: 0.6927076578140259] [G loss: 0.7096262574195862] [ER loss: 0.0012854636879637837]\n",
      "[Epoch 500/10000] [D loss: 0.6927520036697388] [G loss: 0.7036418318748474] [ER loss: 0.0011206910712644458]\n",
      "[Epoch 600/10000] [D loss: 0.6929967403411865] [G loss: 0.7021899819374084] [ER loss: 0.0010349134681746364]\n",
      "[Epoch 700/10000] [D loss: 0.6932814717292786] [G loss: 0.6996368765830994] [ER loss: 0.000968844338785857]\n",
      "[Epoch 800/10000] [D loss: 0.6932722330093384] [G loss: 0.6992948055267334] [ER loss: 0.0009107588557526469]\n",
      "[Epoch 900/10000] [D loss: 0.6931585073471069] [G loss: 0.6978052854537964] [ER loss: 0.0008576600812375546]\n",
      "[Epoch 1000/10000] [D loss: 0.6932262778282166] [G loss: 0.6958199143409729] [ER loss: 0.0008086220477707684]\n",
      "[Epoch 1100/10000] [D loss: 0.6932833790779114] [G loss: 0.6941602826118469] [ER loss: 0.0007635396905243397]\n",
      "[Epoch 1200/10000] [D loss: 0.693249523639679] [G loss: 0.6957589983940125] [ER loss: 0.0007226677844300866]\n",
      "[Epoch 1300/10000] [D loss: 0.69317227602005] [G loss: 0.6934779286384583] [ER loss: 0.0006862090085633099]\n",
      "[Epoch 1400/10000] [D loss: 0.6931659579277039] [G loss: 0.6957557201385498] [ER loss: 0.0006540138856507838]\n",
      "[Epoch 1500/10000] [D loss: 0.6931643486022949] [G loss: 0.6944487690925598] [ER loss: 0.0006255529006011784]\n",
      "[Epoch 1600/10000] [D loss: 0.6931764483451843] [G loss: 0.6941272020339966] [ER loss: 0.0006001130677759647]\n",
      "[Epoch 1700/10000] [D loss: 0.6931768655776978] [G loss: 0.6931565999984741] [ER loss: 0.0005770173738710582]\n",
      "[Epoch 1800/10000] [D loss: 0.69347083568573] [G loss: 0.695976734161377] [ER loss: 0.0005557381664402783]\n",
      "[Epoch 1900/10000] [D loss: 0.6932279467582703] [G loss: 0.6968860626220703] [ER loss: 0.0005359111237339675]\n",
      "[Epoch 2000/10000] [D loss: 0.6932398080825806] [G loss: 0.6943730115890503] [ER loss: 0.0005173050449229777]\n",
      "[Epoch 2100/10000] [D loss: 0.6931696534156799] [G loss: 0.6935608386993408] [ER loss: 0.0004997848300263286]\n",
      "[Epoch 2200/10000] [D loss: 0.693189263343811] [G loss: 0.6938823461532593] [ER loss: 0.00048327803961001337]\n",
      "[Epoch 2300/10000] [D loss: 0.6931936740875244] [G loss: 0.6939905285835266] [ER loss: 0.0004677480610553175]\n",
      "[Epoch 2400/10000] [D loss: 0.6931896209716797] [G loss: 0.6943095326423645] [ER loss: 0.00045317300828173757]\n",
      "[Epoch 2500/10000] [D loss: 0.6931893825531006] [G loss: 0.6941072344779968] [ER loss: 0.0004395312862470746]\n",
      "[Epoch 2600/10000] [D loss: 0.693176805973053] [G loss: 0.694165825843811] [ER loss: 0.00042679329635575414]\n",
      "[Epoch 2700/10000] [D loss: 0.6931883096694946] [G loss: 0.6942482590675354] [ER loss: 0.0004149191081523895]\n",
      "[Epoch 2800/10000] [D loss: 0.693160891532898] [G loss: 0.6935202479362488] [ER loss: 0.00040385863394476473]\n",
      "[Epoch 2900/10000] [D loss: 0.6931618452072144] [G loss: 0.693609893321991] [ER loss: 0.00039355349144898355]\n",
      "[Epoch 3000/10000] [D loss: 0.6931678056716919] [G loss: 0.6937012672424316] [ER loss: 0.0003839386918116361]\n",
      "[Epoch 3100/10000] [D loss: 0.6931658387184143] [G loss: 0.6937187910079956] [ER loss: 0.00037494461867026985]\n",
      "[Epoch 3200/10000] [D loss: 0.6931685209274292] [G loss: 0.6935641169548035] [ER loss: 0.00036650002584792674]\n",
      "[Epoch 3300/10000] [D loss: 0.6931555271148682] [G loss: 0.6944873929023743] [ER loss: 0.00035853456938639283]\n",
      "[Epoch 3400/10000] [D loss: 0.6931717991828918] [G loss: 0.6925356984138489] [ER loss: 0.00035098055377602577]\n",
      "[Epoch 3500/10000] [D loss: 0.6932352781295776] [G loss: 0.6967501640319824] [ER loss: 0.000343773775966838]\n",
      "[Epoch 3600/10000] [D loss: 0.6932802796363831] [G loss: 0.6894082427024841] [ER loss: 0.0003368545148987323]\n",
      "[Epoch 3700/10000] [D loss: 0.693241536617279] [G loss: 0.6916880011558533] [ER loss: 0.00033016863744705915]\n",
      "[Epoch 3800/10000] [D loss: 0.6931543350219727] [G loss: 0.6937782168388367] [ER loss: 0.00032366911182180047]\n",
      "[Epoch 3900/10000] [D loss: 0.6931464672088623] [G loss: 0.6937795281410217] [ER loss: 0.0003173166769556701]\n",
      "[Epoch 4000/10000] [D loss: 0.6931464672088623] [G loss: 0.6937159299850464] [ER loss: 0.00031108042458072305]\n",
      "[Epoch 4100/10000] [D loss: 0.6931464672088623] [G loss: 0.6935889720916748] [ER loss: 0.00030493835220113397]\n",
      "[Epoch 4200/10000] [D loss: 0.693146824836731] [G loss: 0.6936182975769043] [ER loss: 0.0002991165383718908]\n",
      "[Epoch 4300/10000] [D loss: 0.6931483149528503] [G loss: 0.6935167908668518] [ER loss: 0.0002934628864750266]\n",
      "[Epoch 4400/10000] [D loss: 0.6931614875793457] [G loss: 0.6934773921966553] [ER loss: 0.00028814427787438035]\n",
      "[Epoch 4500/10000] [D loss: 0.6931539177894592] [G loss: 0.6936511993408203] [ER loss: 0.00028307619504630566]\n",
      "[Epoch 4600/10000] [D loss: 0.6931515336036682] [G loss: 0.6938514709472656] [ER loss: 0.0002783288946375251]\n",
      "[Epoch 4700/10000] [D loss: 0.6931506991386414] [G loss: 0.6934916973114014] [ER loss: 0.0002739490009844303]\n",
      "[Epoch 4800/10000] [D loss: 0.693152129650116] [G loss: 0.6935609579086304] [ER loss: 0.0002698739990592003]\n",
      "[Epoch 4900/10000] [D loss: 0.6931705474853516] [G loss: 0.6939889788627625] [ER loss: 0.0002660518221091479]\n",
      "[Epoch 5000/10000] [D loss: 0.6931761503219604] [G loss: 0.6937826871871948] [ER loss: 0.00026251666713505983]\n",
      "[Epoch 5100/10000] [D loss: 0.6931549310684204] [G loss: 0.6931815147399902] [ER loss: 0.00025930310948751867]\n",
      "[Epoch 5200/10000] [D loss: 0.6931532621383667] [G loss: 0.6935261487960815] [ER loss: 0.00025626091519370675]\n",
      "[Epoch 5300/10000] [D loss: 0.6931673288345337] [G loss: 0.6935223937034607] [ER loss: 0.00025339305284433067]\n",
      "[Epoch 5400/10000] [D loss: 0.6931849718093872] [G loss: 0.6942733526229858] [ER loss: 0.00025077929603867233]\n",
      "[Epoch 5500/10000] [D loss: 0.6931806802749634] [G loss: 0.6922059059143066] [ER loss: 0.0002482790150679648]\n",
      "[Epoch 5600/10000] [D loss: 0.69315505027771] [G loss: 0.6938328146934509] [ER loss: 0.00024608842795714736]\n",
      "[Epoch 5700/10000] [D loss: 0.6931493282318115] [G loss: 0.6932854056358337] [ER loss: 0.0002436209615552798]\n",
      "[Epoch 5800/10000] [D loss: 0.6931551694869995] [G loss: 0.693090558052063] [ER loss: 0.00024150147510226816]\n",
      "[Epoch 5900/10000] [D loss: 0.6931521892547607] [G loss: 0.693773627281189] [ER loss: 0.00024924500030465424]\n",
      "[Epoch 6000/10000] [D loss: 0.6931568384170532] [G loss: 0.6934419274330139] [ER loss: 0.0002375257172388956]\n",
      "[Epoch 6100/10000] [D loss: 0.6931600570678711] [G loss: 0.6932238340377808] [ER loss: 0.00023568174219690263]\n",
      "[Epoch 6200/10000] [D loss: 0.6931637525558472] [G loss: 0.693566083908081] [ER loss: 0.00023392532602883875]\n",
      "[Epoch 6300/10000] [D loss: 0.6931604146957397] [G loss: 0.6931803226470947] [ER loss: 0.00023328526003751904]\n",
      "[Epoch 6400/10000] [D loss: 0.6931513547897339] [G loss: 0.6930396556854248] [ER loss: 0.00023058961960487068]\n",
      "[Epoch 6500/10000] [D loss: 0.6931487917900085] [G loss: 0.6935126185417175] [ER loss: 0.00022929591068532318]\n",
      "[Epoch 6600/10000] [D loss: 0.693152666091919] [G loss: 0.6934645175933838] [ER loss: 0.00022817272110842168]\n",
      "[Epoch 6700/10000] [D loss: 0.693152666091919] [G loss: 0.6934535503387451] [ER loss: 0.0002265747607452795]\n",
      "[Epoch 6800/10000] [D loss: 0.6931498050689697] [G loss: 0.6936487555503845] [ER loss: 0.0002253811981063336]\n",
      "[Epoch 6900/10000] [D loss: 0.6931496858596802] [G loss: 0.6933973431587219] [ER loss: 0.0002232785918749869]\n",
      "[Epoch 7000/10000] [D loss: 0.6931523084640503] [G loss: 0.6933236718177795] [ER loss: 0.00022222765255719423]\n",
      "[Epoch 7100/10000] [D loss: 0.6931501626968384] [G loss: 0.6932516098022461] [ER loss: 0.0002209381345892325]\n",
      "[Epoch 7200/10000] [D loss: 0.6931560039520264] [G loss: 0.6930586099624634] [ER loss: 0.0002197593857999891]\n",
      "[Epoch 7300/10000] [D loss: 0.6931548118591309] [G loss: 0.6933766603469849] [ER loss: 0.00021834192739333957]\n",
      "[Epoch 7400/10000] [D loss: 0.6931562423706055] [G loss: 0.6937369108200073] [ER loss: 0.0002172162930946797]\n",
      "[Epoch 7500/10000] [D loss: 0.6931520104408264] [G loss: 0.6929534077644348] [ER loss: 0.00021651931456290185]\n",
      "[Epoch 7600/10000] [D loss: 0.6931475400924683] [G loss: 0.6933889985084534] [ER loss: 0.00021507716155610979]\n",
      "[Epoch 7700/10000] [D loss: 0.6931531429290771] [G loss: 0.6932489275932312] [ER loss: 0.00021416859817691147]\n",
      "[Epoch 7800/10000] [D loss: 0.6931624412536621] [G loss: 0.6938477158546448] [ER loss: 0.00021303938410710543]\n",
      "[Epoch 7900/10000] [D loss: 0.6932128071784973] [G loss: 0.6900930404663086] [ER loss: 0.00021205820667091757]\n",
      "[Epoch 8000/10000] [D loss: 0.6931489706039429] [G loss: 0.6931938529014587] [ER loss: 0.00021111445676069707]\n",
      "[Epoch 8100/10000] [D loss: 0.6931477785110474] [G loss: 0.693272590637207] [ER loss: 0.00021021316933911294]\n",
      "[Epoch 8200/10000] [D loss: 0.6931474208831787] [G loss: 0.6932669878005981] [ER loss: 0.000209251040359959]\n",
      "[Epoch 8300/10000] [D loss: 0.6931474208831787] [G loss: 0.6932684779167175] [ER loss: 0.0002085591695504263]\n",
      "[Epoch 8400/10000] [D loss: 0.6931474208831787] [G loss: 0.6932656168937683] [ER loss: 0.00020750371913891286]\n",
      "[Epoch 8500/10000] [D loss: 0.6931473016738892] [G loss: 0.6932745575904846] [ER loss: 0.000206667828024365]\n",
      "[Epoch 8600/10000] [D loss: 0.6931474208831787] [G loss: 0.6932312250137329] [ER loss: 0.00020595945534296334]\n",
      "[Epoch 8700/10000] [D loss: 0.6931473016738892] [G loss: 0.693267285823822] [ER loss: 0.00020510896865744144]\n",
      "[Epoch 8800/10000] [D loss: 0.6931472420692444] [G loss: 0.693249523639679] [ER loss: 0.00020424916874617338]\n",
      "[Epoch 8900/10000] [D loss: 0.6931473016738892] [G loss: 0.6932831406593323] [ER loss: 0.00020368440891616046]\n",
      "[Epoch 9000/10000] [D loss: 0.6931472420692444] [G loss: 0.6932640671730042] [ER loss: 0.00020274300186429173]\n",
      "[Epoch 9100/10000] [D loss: 0.6931477785110474] [G loss: 0.6933318972587585] [ER loss: 0.0002023217675741762]\n",
      "[Epoch 9200/10000] [D loss: 0.6931474208831787] [G loss: 0.6932619214057922] [ER loss: 0.00020234592375345528]\n",
      "[Epoch 9300/10000] [D loss: 0.6931471824645996] [G loss: 0.6932471394538879] [ER loss: 0.00020055500499438494]\n",
      "[Epoch 9400/10000] [D loss: 0.6931471824645996] [G loss: 0.6932361125946045] [ER loss: 0.00019985443213954568]\n",
      "[Epoch 9500/10000] [D loss: 0.6931474208831787] [G loss: 0.6932006478309631] [ER loss: 0.0001991904864553362]\n",
      "[Epoch 9600/10000] [D loss: 0.6931472420692444] [G loss: 0.6933112144470215] [ER loss: 0.00020171979849692434]\n",
      "[Epoch 9700/10000] [D loss: 0.6931471228599548] [G loss: 0.6932403445243835] [ER loss: 0.00019788903591688722]\n",
      "[Epoch 9800/10000] [D loss: 0.6931471824645996] [G loss: 0.6932013034820557] [ER loss: 0.0001972499885596335]\n",
      "[Epoch 9900/10000] [D loss: 0.6931471824645996] [G loss: 0.6932587027549744] [ER loss: 0.00019662307749968022]\n",
      "torch.Size([10000, 17, 1]) torch.Size([10000, 206])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vasil\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (170000x1 and 17x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 243\u001b[0m\n\u001b[0;32m    241\u001b[0m test_spectra_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(data_scaled_sp\u001b[38;5;241m.\u001b[39mT, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28mprint\u001b[39m(test_photometry_data\u001b[38;5;241m.\u001b[39mshape, test_spectra_data\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m--> 243\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_photometry_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_spectra_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphotometry_wavelengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspectra_wavelengths\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 186\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, test_photometry_data, test_spectra_data, photometry_wavelengths, spectra_wavelengths)\u001b[0m\n\u001b[0;32m    182\u001b[0m model_gan\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;66;03m# Generate predictions\u001b[39;00m\n\u001b[1;32m--> 186\u001b[0m     generated_spectra \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_gan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_photometry_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;66;03m# Calculate metrics\u001b[39;00m\n\u001b[0;32m    189\u001b[0m     mse \u001b[38;5;241m=\u001b[39m mean_squared_error(test_spectra_data\u001b[38;5;241m.\u001b[39mcpu(), generated_spectra\u001b[38;5;241m.\u001b[39mcpu())\n",
      "Cell \u001b[1;32mIn[3], line 69\u001b[0m, in \u001b[0;36mPhotometryToSpectraModel.forward_generator\u001b[1;34m(self, photometry)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_generator\u001b[39m(\u001b[38;5;28mself\u001b[39m, photometry):\n\u001b[1;32m---> 69\u001b[0m     latent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphotometry\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m     generated_spectra \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerator(latent)\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generated_spectra\n",
      "File \u001b[1;32mc:\\Users\\vasil\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vasil\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 18\u001b[0m, in \u001b[0;36mEmbeddingNetwork.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtanh(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\vasil\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vasil\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vasil\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (170000x1 and 17x64)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "### Embedding and Recovery Networks ###\n",
    "class EmbeddingNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(EmbeddingNetwork, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, latent_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.tanh(self.fc(x))\n",
    "\n",
    "class RecoveryNetwork(nn.Module):\n",
    "    def __init__(self, latent_dim, output_dim):\n",
    "        super(RecoveryNetwork, self).__init__()\n",
    "        self.fc = nn.Linear(latent_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "### Generator with Transformer Encoder ###\n",
    "class TransformerGenerator(nn.Module):\n",
    "    def __init__(self, latent_dim, output_dim, nhead, hidden_dim, num_layers):\n",
    "        super(TransformerGenerator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.transformer_layer = TransformerEncoderLayer(d_model=latent_dim, nhead=nhead, dim_feedforward=hidden_dim)\n",
    "        self.transformer = TransformerEncoder(self.transformer_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(latent_dim, output_dim)\n",
    "\n",
    "    def forward(self, z):\n",
    "        # Apply transformer and map to output space\n",
    "        transformed = self.transformer(z)\n",
    "        return self.fc(transformed)\n",
    "\n",
    "### Discriminator ###\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "### Full TimeGAN-like Model ###\n",
    "class PhotometryToSpectraModel(nn.Module):\n",
    "    def __init__(self, photometry_dim, spectra_dim, latent_dim, transformer_hidden_dim, transformer_nhead, transformer_layers):\n",
    "        super(PhotometryToSpectraModel, self).__init__()\n",
    "        self.embedding = EmbeddingNetwork(input_dim=photometry_dim, latent_dim=latent_dim)\n",
    "        self.generator = TransformerGenerator(latent_dim=latent_dim, output_dim=spectra_dim, nhead=transformer_nhead, hidden_dim=transformer_hidden_dim, num_layers=transformer_layers)\n",
    "        self.recovery = RecoveryNetwork(latent_dim=latent_dim, output_dim=spectra_dim)\n",
    "        self.discriminator = Discriminator(input_dim=spectra_dim)\n",
    "\n",
    "    def forward_generator(self, photometry):\n",
    "        latent = self.embedding(photometry)\n",
    "        generated_spectra = self.generator(latent)\n",
    "        return generated_spectra\n",
    "\n",
    "    def forward_discriminator(self, spectra):\n",
    "        return self.discriminator(spectra)\n",
    "\n",
    "    def forward_embedding_recovery(self, photometry):\n",
    "        latent = self.embedding(photometry)\n",
    "        return self.recovery(latent)\n",
    "\n",
    "### Training Function with Supervised Loss ###\n",
    "def train_model(model, photometry_data, spectra_data, epochs=10000):\n",
    "    criterion = nn.MSELoss()          # Supervised loss\n",
    "    adversarial_loss = nn.BCELoss()   # Adversarial loss\n",
    "\n",
    "    optimizer_G = optim.Adam(model.generator.parameters(), lr=0.001)\n",
    "    optimizer_D = optim.Adam(model.discriminator.parameters(), lr=0.001)\n",
    "    optimizer_ER = optim.Adam(list(model.embedding.parameters()) + list(model.recovery.parameters()), lr=0.001)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Adversarial ground truths\n",
    "        valid = torch.ones((spectra_data.shape[0], 1), requires_grad=False).to(device)\n",
    "        fake = torch.zeros((spectra_data.shape[0], 1), requires_grad=False).to(device)\n",
    "\n",
    "        # ========================= Train Generator with Supervised Loss =========================\n",
    "        optimizer_G.zero_grad()\n",
    "        generated_spectra = model.forward_generator(photometry_data)\n",
    "        \n",
    "        # Supervised loss between generated spectra and real spectra\n",
    "        g_loss_supervised = criterion(generated_spectra, spectra_data)\n",
    "        \n",
    "        # Adversarial loss for generator\n",
    "        g_loss_adversarial = adversarial_loss(model.forward_discriminator(generated_spectra), valid)\n",
    "        \n",
    "        # Total generator loss\n",
    "        g_loss = g_loss_supervised + g_loss_adversarial\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ========================= Train Discriminator =========================\n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        real_loss = adversarial_loss(model.forward_discriminator(spectra_data), valid)\n",
    "        fake_loss = adversarial_loss(model.forward_discriminator(generated_spectra.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # ========================= Train Embedding and Recovery Networks =========================\n",
    "        optimizer_ER.zero_grad()\n",
    "        \n",
    "        recovered_spectra = model.forward_embedding_recovery(photometry_data)\n",
    "        er_loss = criterion(recovered_spectra, spectra_data)  # Supervised loss for embedding/recovery\n",
    "        \n",
    "        er_loss.backward()\n",
    "        optimizer_ER.step()\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"[Epoch {epoch}/{epochs}] [D loss: {d_loss.item()}] [G loss: {g_loss.item()}] [ER loss: {er_loss.item()}]\")\n",
    "    torch.save(model.state_dict(), \"./gan_model.pth\")\n",
    "\n",
    "# Instantiate the model\n",
    "photometry_dim = 17\n",
    "spectra_dim = 206\n",
    "latent_dim = 64\n",
    "transformer_hidden_dim = 128\n",
    "transformer_nhead = 4\n",
    "transformer_layers = 4\n",
    "\n",
    "model = PhotometryToSpectraModel(\n",
    "    photometry_dim=photometry_dim, \n",
    "    spectra_dim=spectra_dim, \n",
    "    latent_dim=latent_dim, \n",
    "    transformer_hidden_dim=transformer_hidden_dim, \n",
    "    transformer_nhead=transformer_nhead, \n",
    "    transformer_layers=transformer_layers\n",
    ").to(device)\n",
    "\n",
    "# Load data\n",
    "df_spectra = pd.read_csv('../data/spectra.csv').T\n",
    "df_spectra.columns = range(len(df_spectra.columns))\n",
    "data_sp = df_spectra.values.astype(np.float64)\n",
    "data_scaled_sp = data_sp / np.max(data_sp)\n",
    "fluxes_sp = data_sp[:, :]  # Shape [10000, 17]\n",
    "\n",
    "df_photo = pd.read_csv('../data/interpolated_spectra.csv').T\n",
    "df_photo.columns = range(len(df_photo.columns))\n",
    "data_ph = df_photo.values.astype(np.float64)\n",
    "data_scaled_ph = data_ph / np.max(data_ph)\n",
    "\n",
    "# Load your photometry and spectra data here\n",
    "photometry_data = data_scaled_ph\n",
    "spectra_data = data_scaled_sp\n",
    "photometry_data = torch.tensor(photometry_data.T, dtype=torch.float32).to(device)\n",
    "spectra_data = torch.tensor(spectra_data.T, dtype=torch.float32).to(device)\n",
    "\n",
    "# Run training\n",
    "train_model(model, photometry_data, spectra_data)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_model(model, test_photometry_data, test_spectra_data, photometry_wavelengths, spectra_wavelengths):\n",
    "    model_gan = PhotometryToSpectraModel(\n",
    "    photometry_dim=photometry_dim, \n",
    "    spectra_dim=spectra_dim, \n",
    "    latent_dim=latent_dim, \n",
    "    transformer_hidden_dim=transformer_hidden_dim, \n",
    "    transformer_nhead=transformer_nhead, \n",
    "    transformer_layers=transformer_layers\n",
    ").to(device)\n",
    "    model_gan.load_state_dict(torch.load(\"./gan_model.pth\", weights_only=True))\n",
    "    model_gan.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Generate predictions\n",
    "        generated_spectra = model_gan.forward_generator(test_photometry_data)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mse = mean_squared_error(test_spectra_data.cpu(), generated_spectra.cpu())\n",
    "        mae = mean_absolute_error(test_spectra_data.cpu(), generated_spectra.cpu())\n",
    "        \n",
    "        print(f\"Test MSE: {mse}\")\n",
    "        print(f\"Test MAE: {mae}\")\n",
    "\n",
    "    # Visualize the comparison for a few samples\n",
    "    n_samples = 2  # Number of samples to visualize\n",
    "    # fig, axes = plt.subplots(n_samples, 1, figsize=(10, 2 * 3))\n",
    "    \n",
    "    # for i in range(n_samples):\n",
    "    real_sample = test_spectra_data[0,:].cpu().numpy()\n",
    "    photometry_data = test_photometry_data[0,:].cpu().numpy()\n",
    "    generated_sample = generated_spectra[0,:].cpu().numpy()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(spectra_wavelengths, real_sample, label='Real Spectra', color='blue', alpha=0.7)\n",
    "    \n",
    "    # Plotting the generated spectra\n",
    "    plt.plot(spectra_wavelengths, generated_sample, label='Generated Spectra', color='orange', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Plotting the photometry points\n",
    "    plt.scatter(photometry_wavelengths, photometry_data, label='Photometry', color='red', s=50)\n",
    "    # axes.set_title(f\"Sample {i+1}\")\n",
    "    # Add labels and legend\n",
    "    plt.xlabel('Wavelength (Âµm)')\n",
    "    plt.ylabel('Flux')\n",
    "    plt.title('GAN: Real vs. Generated Spectra with Photometry Points')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# After training, evaluate on a test dataset\n",
    "df_wavelengths = pd.read_csv(\"../data/interpolated_spectra.csv\").T\n",
    "df_wavelengths.reset_index(inplace=True)\n",
    "df_wavelengths.columns = range(len(df_wavelengths.columns))\n",
    "df_wavelengths = df_wavelengths.values.astype(np.float64)\n",
    "df_wavelengths_scaled = df_wavelengths / np.max(df_wavelengths)\n",
    "data_wavelengths_photo = df_wavelengths[:, 0]  # Shape: [17]\n",
    "fluxes_ph = data_ph[:, 0:]  # Transpose to get shape [10000, 17]\n",
    "# Spectra\n",
    "df_wavelengths_spectra = pd.read_csv(\"../data/spectra.csv\").T\n",
    "df_wavelengths_spectra.reset_index(inplace=True)\n",
    "df_wavelengths_spectra.columns = range(len(df_wavelengths_spectra.columns))\n",
    "df_wavelengths_spectra = df_wavelengths_spectra.values.astype(np.float64)\n",
    "df_wavelengths_scaled_spectra = df_wavelengths_spectra / np.max(df_wavelengths_spectra)\n",
    "data_wavelengths_spectra = df_wavelengths_spectra[:, 0]  # Shape: [17]\n",
    "\n",
    "photometry_wavelengths = data_wavelengths_photo   # 17 photometry wavelength points\n",
    "spectra_wavelengths = data_wavelengths_spectra   # 17 photometry wavelength points\n",
    "test_photometry_data = torch.tensor(data_scaled_ph.T, dtype=torch.float32).unsqueeze(2).to(device)  # Reshape if necessary\n",
    "test_spectra_data = torch.tensor(data_scaled_sp.T, dtype=torch.float32).to(device)\n",
    "print(test_photometry_data.shape, test_spectra_data.shape)\n",
    "evaluate_model(model, test_photometry_data, test_spectra_data, photometry_wavelengths, spectra_wavelengths)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
